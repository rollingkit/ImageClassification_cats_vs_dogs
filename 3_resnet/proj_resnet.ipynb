{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pe2mEAv6T88k"
   },
   "source": [
    "# ====Method 3: ResNet ===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tvSUVtaaUFr"
   },
   "source": [
    "# ResNet\n",
    "\n",
    "Applying residual blocks is generally useful for neural networks where there are many layers and as a result vanishing gradient problem. \n",
    "\n",
    "We have applied AlexNet which is really only composed of 8 layers out of which there are only 4 convolutional layers. \n",
    "\n",
    "The benefits of ResNet are better reaped in networks with much more layers. It is also simpler to apply residual blocks in those networks where there are at least two or more convolutional layers with the same number of filters as then the output after one layer can be added with the output after two or more such layers and there would not be dimension mismatch. \n",
    "\n",
    "Below, we have applied ResNet to a plain neural network that has 34 layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGiu53IFbID1"
   },
   "source": [
    "# ResNet on 34-layer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1620506947873,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "0mTps9IiaXHg"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, AveragePooling2D, concatenate\n",
    "from keras.layers import Input, concatenate\n",
    "from keras.layers import Add\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1620506949465,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "ZU1Bmcqybrme"
   },
   "outputs": [],
   "source": [
    "#Function for convolution with BatchNormalization\n",
    "def Conv2d_BN(x, nb_filter, kernel_size, padding='same', strides=(1,1), name=None):\n",
    "  if name is not None:\n",
    "    bn_name = name + '_bn'\n",
    "    conv_name = name + '_conv'\n",
    "  else:\n",
    "    bn_name = None\n",
    "    conv_name = None\n",
    "  \n",
    "  x = Conv2D(nb_filter,kernel_size, padding=padding,strides=strides,activation='relu',name=conv_name)(x)\n",
    "  x = BatchNormalization(axis=3, name=bn_name)(x)\n",
    "  #axis =3 meaning to apply normalization over channels\n",
    "  return x\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 152,
     "status": "ok",
     "timestamp": 1620506950020,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "xp0mXX79cf_M"
   },
   "outputs": [],
   "source": [
    "#Function for residual block\n",
    "def Residual_Block(input_model,nb_filter,kernel_size, strides=(1,1), with_conv_shortcut=False):\n",
    "  x = Conv2d_BN(input_model,nb_filter=nb_filter, kernel_size=kernel_size, strides=strides, padding='same')\n",
    "\n",
    "  if with_conv_shortcut:\n",
    "    shortcut = Conv2d_BN(input_model, nb_filter=nb_filter, strides=strides, kernel_size = kernel_size)\n",
    "    x = Add()([x, shortcut])\n",
    "    return x\n",
    "  else:\n",
    "    x = Add()([x, input_model])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgnA3DXdf55S"
   },
   "source": [
    "We are going to apply a hop over 2 convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1620506952482,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "pu1zfGJqfRAR"
   },
   "outputs": [],
   "source": [
    "def ResNet34(width,height,depth):\n",
    "  Img = Input(shape=(width, height, depth))\n",
    "\n",
    "  x = Conv2d_BN(Img,nb_filter=64,kernel_size=(7,7), strides=(2,2), padding='same')\n",
    "  x = MaxPooling2D(pool_size=(3,3),strides=(2,2), padding='same')(x)\n",
    "\n",
    "  x = Residual_Block(x,nb_filter=64,kernel_size=(3,3))\n",
    "  x = Residual_Block(x,nb_filter=64,kernel_size=(3,3))\n",
    "  x = Residual_Block(x,nb_filter=64,kernel_size=(3,3))\n",
    "\n",
    "  x = Residual_Block(x,nb_filter=128,kernel_size=(3,3),strides=(2,2),with_conv_shortcut=True)\n",
    "  x = Residual_Block(x,nb_filter=128,kernel_size=(3,3))\n",
    "  x = Residual_Block(x,nb_filter=128,kernel_size=(3,3))\n",
    "  x = Residual_Block(x,nb_filter=128,kernel_size=(3,3))\n",
    "\n",
    "  x = Residual_Block(x,nb_filter=256,kernel_size=(3,3),strides=(2,2),with_conv_shortcut=True)\n",
    "  x = Residual_Block(x,nb_filter=256,kernel_size=(3,3))\n",
    "  x = Residual_Block(x,nb_filter=256,kernel_size=(3,3))\n",
    "  x = Residual_Block(x,nb_filter=256,kernel_size=(3,3))\n",
    "  x = Residual_Block(x,nb_filter=256,kernel_size=(3,3))\n",
    "  x = Residual_Block(x,nb_filter=256,kernel_size=(3,3))\n",
    "\n",
    "  x = Residual_Block(x,nb_filter=512,kernel_size=(3,3),strides=(2,2),with_conv_shortcut=(True))\n",
    "  x = Residual_Block(x,nb_filter=512,kernel_size=(3,3))\n",
    "  x = Residual_Block(x,nb_filter=512,kernel_size=(3,3))\n",
    "\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "  model = Model(Img,x)\n",
    "\n",
    "  return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1620506954707,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "XWEGdCxZlzpa"
   },
   "outputs": [],
   "source": [
    "resnet_model = ResNet34(150,150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1620506956676,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "SYoY6h-srmZt",
    "outputId": "95af2096-3b00-4416-bf9d-defd70c23631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 75, 75, 64)   9472        input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 75, 75, 64)   256         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 38, 38, 64)   0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 38, 38, 64)   36928       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 38, 38, 64)   256         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 38, 38, 64)   0           batch_normalization_79[0][0]     \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 38, 38, 64)   36928       add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 38, 38, 64)   256         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 38, 38, 64)   0           batch_normalization_80[0][0]     \n",
      "                                                                 add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 38, 38, 64)   36928       add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 38, 38, 64)   256         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 38, 38, 64)   0           batch_normalization_81[0][0]     \n",
      "                                                                 add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 19, 19, 128)  73856       add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 19, 19, 128)  73856       add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 19, 19, 128)  512         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 19, 19, 128)  512         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 19, 19, 128)  0           batch_normalization_82[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 19, 19, 128)  147584      add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 19, 19, 128)  512         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 19, 19, 128)  0           batch_normalization_84[0][0]     \n",
      "                                                                 add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 19, 19, 128)  147584      add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 19, 19, 128)  512         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 19, 19, 128)  0           batch_normalization_85[0][0]     \n",
      "                                                                 add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 19, 19, 128)  147584      add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 19, 19, 128)  512         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 19, 19, 128)  0           batch_normalization_86[0][0]     \n",
      "                                                                 add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 10, 10, 256)  295168      add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 10, 10, 256)  295168      add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 10, 10, 256)  1024        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 10, 10, 256)  1024        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 10, 10, 256)  0           batch_normalization_87[0][0]     \n",
      "                                                                 batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 10, 10, 256)  590080      add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 10, 10, 256)  1024        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 10, 10, 256)  0           batch_normalization_89[0][0]     \n",
      "                                                                 add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 10, 10, 256)  590080      add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 10, 10, 256)  1024        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 10, 10, 256)  0           batch_normalization_90[0][0]     \n",
      "                                                                 add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 10, 10, 256)  590080      add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 10, 10, 256)  1024        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 10, 10, 256)  0           batch_normalization_91[0][0]     \n",
      "                                                                 add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 10, 10, 256)  590080      add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 10, 10, 256)  1024        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 10, 10, 256)  0           batch_normalization_92[0][0]     \n",
      "                                                                 add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 10, 10, 256)  590080      add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 10, 10, 256)  1024        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 10, 10, 256)  0           batch_normalization_93[0][0]     \n",
      "                                                                 add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 5, 5, 512)    1180160     add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 5, 5, 512)    1180160     add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 5, 512)    2048        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 5, 5, 512)    2048        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 5, 5, 512)    0           batch_normalization_94[0][0]     \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 5, 5, 512)    2359808     add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 5, 5, 512)    2048        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 5, 5, 512)    0           batch_normalization_96[0][0]     \n",
      "                                                                 add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 5, 5, 512)    2359808     add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 5, 5, 512)    2048        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, 5, 5, 512)    0           batch_normalization_97[0][0]     \n",
      "                                                                 add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 512)          0           add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            513         global_average_pooling2d_3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 11,350,849\n",
      "Trainable params: 11,341,377\n",
      "Non-trainable params: 9,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2taot9fs8BV"
   },
   "source": [
    "Now, we can load in the data like for other models and go ahead an train the model on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22019,
     "status": "ok",
     "timestamp": 1620507022257,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "CnP2EFhisqmM",
    "outputId": "9dc3acdf-71e6-40af-8287-961002804eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1620507080459,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "QWCeObPQvn1i"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "TRAINDIR = 'gdrive/MyDrive/ee_628/proj/train/'\n",
    "cat_folder = 'cat'\n",
    "dog_folder = 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1620507172760,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "YzKgT46Lv7Xl"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10,\n",
    "                             shear_range=0.2,\n",
    "                             rescale=1./255,\n",
    "                             validation_split=0.25)\n",
    "IMG_H = 150\n",
    "IMG_W = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59272,
     "status": "ok",
     "timestamp": 1620507301521,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "CjcdJ8S_wR6Y",
    "outputId": "9f917b92-dafe-494e-bd03-4e5c5f3af3b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18750 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(TRAINDIR,\n",
    "                                              target_size=(IMG_H,IMG_W),\n",
    "                                              batch_size=100,\n",
    "                                              class_mode='binary',\n",
    "                                              subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1148,
     "status": "ok",
     "timestamp": 1620507437627,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "rW8vP36gwi7R",
    "outputId": "ca8a9438-187a-420a-9ad9-d095047f10f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6250 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_directory(TRAINDIR,\n",
    "                                            target_size=(IMG_H, IMG_W),\n",
    "                                            batch_size=100,\n",
    "                                            class_mode='binary',\n",
    "                                            subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1620507518128,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "a9GmGtD5xQvd"
   },
   "outputs": [],
   "source": [
    "resnet_model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8096319,
     "status": "ok",
     "timestamp": 1620515654201,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "gXsEAOenxjML",
    "outputId": "a72d3b8c-425e-44cf-f28e-e9a08b58c8d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 8063s 43s/step - loss: 1.1461 - accuracy: 0.5742 - val_loss: 0.8520 - val_accuracy: 0.5517\n"
     ]
    }
   ],
   "source": [
    "hist_resnet = resnet_model.fit_generator(train_generator, validation_data=val_generator, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1620516373266,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "scJ_hH0eQ3tQ",
    "outputId": "fd3aa639-02ef-4447-8936-e4c89c3ba503"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 529098,
     "status": "ok",
     "timestamp": 1620516245069,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "iuIc2hUQxv_E",
    "outputId": "c1cc2594-699f-425c-d5a5-00f05fed70e3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8639941215515137, 0.5518933534622192]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.evaluate_generator(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177599,
     "status": "ok",
     "timestamp": 1620516573970,
     "user": {
      "displayName": "Sivankit Bhanot",
      "photoUrl": "",
      "userId": "05844894863592949286"
     },
     "user_tz": 240
    },
    "id": "wdLFfgBnTYHz",
    "outputId": "31390521-4a1f-49df-f205-6145fe890e30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8517088890075684, 0.5542399883270264]"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.evaluate_generator(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVbcjKH8Td0c",
    "outputId": "47379c8a-de71-4f3d-9b09-c70df11b1068"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "188/188 [==============================] - 2558s 14s/step - loss: 0.5759 - accuracy: 0.7007 - val_loss: 0.9727 - val_accuracy: 0.5896\n",
      "Epoch 2/20\n",
      " 53/188 [=======>......................] - ETA: 28:27 - loss: 0.5229 - accuracy: 0.7331"
     ]
    }
   ],
   "source": [
    "hist2_resnet = resnet_model.fit_generator(train_generator, validation_data=val_generator, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihfW7-JlUJ3Y"
   },
   "source": [
    "# Conclusions:\n",
    "\n",
    "\n",
    "| | Train Performance | Validation Performance |\n",
    "| :-: | :-: | :-:|\n",
    "| AlexNet | 71.4% | 68.5% |\n",
    "| Transfer Learning with VGG16 | 50.0% | 50.0% |\n",
    "| ResNet34 | 55.2% | 55.4% |\n",
    "\n",
    "\n",
    "Due to time constraints, not many epochs could be run for each of the networks tried and tested here. \n",
    "For the first method, AlexNet, we observed that there was about 71% accuracy on training set and 68% on validation set. This shows that we are still underfitting and that there could be more epochs run to reach a higher accuracy on the validation set before trying out the network on an unseen test set. \n",
    "In the second method, we observed some unexpected results as the accuracy of validation set seemed to stay constant at 50% which means that there clearly may be some error and the network perhaps needs more scrutiny. For transfer learning, we imported the VGG16 network's beginning convolutional layers with the weights after it has been trained on ImageNet. ImageNet is a dataset that consists of color (3 channels) images of various classes (~ 200) including animals. Seeings as these are color images which include animals, it seemed like a good fit to have a model trained on this dataset for transfer learning and applying it to our data of cats and dogs. In addition to importing the top of the trained VGG16 neural network architecture, 4 dense layers were attached at the end and then classification using sigmoid was done. Having this many fully connected layers could have in turn caused the poor performance for this method. This was expected to be the best performer and therefore it was a bit surprising to see its lower performance. \n",
    "For the third method, initially it was desired to apply residual blocks to known CNNs such as AlexNet. However, when designing the ResNet, it was quickly realized that a shortcut or skip would have to be done over at least two convolutional layers and both these layers would have to have equal number of filters so that the output could be added with the input and there was no dimension mismatch. (Note that we could still perform addition on input and output for the cases where the number of filters are different, by considering different padding, but this would be a complicated process and something worth considering for a future separate project) Therefore, instead the ResNet was applied to a 34-layer network. In this the 'skips' or shortcuts were applied after 2 identical convolutional layers. \n",
    "\n",
    "For each of the above cases, one of the biggest constraints has been of time. The number of epochs has been limited to 20, which in some cases may not be nearly enough. \n",
    "The ResNet model seems to be the best performer after just 1 epoch. It is currently being run for 20 epochs. At the time of the submission of this report, it has not completed those 20 epochs and the results are therefore awaited for it. \n",
    "The results posted in the table above are those after just 1 epoch. \n",
    "\n",
    "# Future Goals:\n",
    "\n",
    "If given more time, it would be worth considering various different parameters on each of these methods. Some of these would include trying out different activation functions. \n",
    "\n",
    "For example, it could be worth to try the LeakyReLU activation function for each of the layers in the AlexNet architecture. \n",
    "It might also be worth looking into trying softmax activation in the last layer rather than sigmoid. This way, for each example, we would achieve two probability values rather than one. These probability values would correspond to the likelihood of each instance belonging to each of the classes. If using this, we would have to consider the categorical_crossentropy loss rather than binary_crossentropy.\n",
    "\n",
    "While considering different parameters for the neural networks, it would also be worth checking the performance variation with different optimizers. Currently the Adam optimizer has been used in all the methods. There are other optimizers such as rmsprop. \n",
    "\n",
    "Due to a number of paramters being present that could be changed and different combinations tested, with more time it would be beneficial to run cross-validation with these parameters for each of the networks to identify the best performing set of hyperparameters. \n",
    "\n",
    "\n",
    "Another important point to consider with more time would be to try less number of dense layers in the transfer learning method. This method in particular requires more investigation as the validation accuracy does not change at all. It could also be that this just requires more epochs before the validation set sees a change in the performance. \n",
    "\n",
    "Finally, it would also be worth to try a combination of ResNet and transfer learning. Currently the second method is a combination of ConvNet and transfer learning. We could also try transfer learning with a ResNet. This would involve training a ResNet on a larger dataset and storing those weight values and then training and running it on the Cats vs Dogs dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UY2OVzLUo1d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNQk7eXHJp7US15UHRbf4HH",
   "collapsed_sections": [],
   "name": "proj_resnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
